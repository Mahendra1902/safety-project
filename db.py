from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import DirectoryLoader, TextLoader, CSVLoader
from langchain.text_splitter import CharacterTextSplitter
import os
import glob

def build_vectordb():
    docs = []

    # --- Load .txt Files ---
    try:
        txt_loader = DirectoryLoader(
            "incident_docs", 
            glob="**/*.txt", 
            loader_cls=TextLoader
        )
        txt_docs = txt_loader.load()
        docs.extend(txt_docs)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to load .txt files: {e}")

    # --- Load .csv Files ---
    try:
        csv_files = glob.glob(os.path.join("incident_docs", "**/*.csv"), recursive=True)
        for csv_file in csv_files:
            loader = CSVLoader(file_path=csv_file)
            csv_docs = loader.load()
            docs.extend(csv_docs)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to load .csv files: {e}")

    print(f"üìÑ Total raw documents loaded: {len(docs)}")

    if not docs:
        print("‚ùå No documents found in 'incident_docs'. Exiting.")
        return

    # --- Split into chunks ---
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = splitter.split_documents(docs)
    print(f"‚úÇÔ∏è Split into {len(split_docs)} chunks.")

    if not split_docs:
        print("‚ùå No content to embed after splitting. Exiting.")
        return

    # --- Embedding + FAISS Index ---
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={"device": "cpu"}  # Change to "cuda" if using GPU
        )
        db = FAISS.from_documents(split_docs, embeddings)
        db.save_local("incident_faiss_index")
        print("‚úÖ Vector DB created and saved as 'incident_faiss_index'")
    except Exception as e:
        print(f"‚ùå Error while building vector DB: {e}")

# Run the builder
if __name__ == "__main__":
    build_vectordb()
